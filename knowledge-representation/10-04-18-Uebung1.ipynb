{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D #import 3d diagram\n",
    "from matplotlib import cm #Colormap import\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect something like this (e.g.): plot_dataframe_with_args([source_data_x,source_data_y,color],[result_data_x, result_data_y, color]) \n",
    "def plot_dataframe_with_args(*args):#(x_source, y_source, color_source, x_results, y_results, color_results, add_offset = False):\n",
    "#     for i in args:\n",
    "#         if i != args[0]:\n",
    "    #plt.figure(figsize=(60, 25))\n",
    "    plt.title('')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    for i in args:\n",
    "        plt.plot(i[0],i[1],\"b*\") \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1)\n",
    " Erstellen Sie zuerst zum Testen Ihrer Lösung automatische Daten,\n",
    "  d.h. Punkte die auf einer Geraden liegen und deren y-Werte mittels eines gaussverteilten \"Rauschen\" von idealen Werten abweichen.\n",
    "  x und y sollen dabei zwei gleichlange numpy-Arrays sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2)\n",
    "   Implementieren Sie die Hypothese (lineares Modell) als Python Funktion:\n",
    "       linear_hypothesis(theta_0, theta_1)\n",
    "   Die Pythonfunktion soll dabei eine Funktion zurückgeben:\n",
    "   -> hypothesis = linear_hypothesis(2., 3.)\n",
    "   ->  print hypothesis(np.array([1., 2.]))\n",
    "   [ 5.  8.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates linear Hypothesis\n",
    "## Params: Changable values like m, n -> theta_0,theta_1\n",
    "##return: hypothesis function with 1 Para (x-values)\n",
    "\n",
    "#Model-Aufbau: f(x) = C + m*x\n",
    "def linear_hypothesis(theta_0, theta_1):\n",
    "    def tmp(x_values):\n",
    "        return np.array([theta_1*x + theta_0 for x in x_values])\n",
    "    return tmp\n",
    "\n",
    "\n",
    "#hypothesis = linear_hypothesis(2.,3.)\n",
    "#print(hypothesis(np.array([1.,3.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3)\n",
    "    Implementieren Sie die Kostenfunktion J als Python Funktion:\n",
    "       def cost_function(hypothesis, x, y):\n",
    "    <br>\n",
    "    <br>\n",
    "    Die Pythonfunktion soll dabei eine Funktion zurückgeben, die\n",
    "    die beiden Parameter theta_0 und theta_1 aufnimmt.\n",
    "    \n",
    "   -> j = cost_function(linear_hypothesis, x, y)\n",
    "   -> print j(2.1, 2.9)\n",
    "   41.20  # Wert abhaengig von x und y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cost function\n",
    "## Params: hypothesis, x , y, hypo+x = y_prediction; y_label = original data\n",
    "\n",
    "\n",
    "#ich verstehe nicht, dass man eine hypothese als parameter nehmen soll aber zusätzlich die costen funktion eine Funktion zurück liefern soll, die gerade die parameter theta0 und theta1 aufnhemen soll, obwohl diese doch schon mit der hypothese gekommen sind\n",
    "def cost_function(hypothesis, x, y): \n",
    "    return lambda theta_0, theta_1 : (1/(2*len(y))* np.sum(np.square(((hypothesis(theta_0,theta_1))(x)) - y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4)\n",
    "   Plotten Sie die Kostenfunktion in der Umgebung des Minimums als Contourplot.\n",
    "   Verwenden Sie hierzu plt.contour(X,Y,Z) und zum Erzeugen des X-Y-Oberflaechengitters meshgrid(..)\n",
    "   <br>\n",
    "   <br>\n",
    "   Beispiel-Code:\n",
    "   <br>\n",
    "   from mpl_toolkits.mplot3d import Axes3D\n",
    "    from matplotlib import cm\n",
    "    from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    ran = 4.\n",
    "    t0 = np.arange(a - ran, a + ran, ran * 0.05)\n",
    "    t1 = np.arange(b - ran, b + ran, ran * 0.05)\n",
    "\n",
    "    C = np.zeros([len(t0),len(t1)])\n",
    "    c = cost_function(linear_hypothesis, x, y)\n",
    "\n",
    "    for i, t_0 in enumerate(t0):\n",
    "    for j, t_1 in enumerate(t1):\n",
    "    C[j][i] = c(t_0, t_1)\n",
    "\n",
    "    T0, T1 = np.meshgrid(t0, t1)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.contour(T0, T1, C)\n",
    "    plt.xlabel('$\\Theta_0$')\n",
    "    plt.ylabel('$\\Theta_1$')\n",
    "    plt.title('Kostenfunktion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contour_plot(cost_function_para,linear_hypothesis_para, x, y):\n",
    "    a=0\n",
    "    b=3\n",
    "    ran = 4.\n",
    "    t0 = np.arange(a - ran, a + ran, ran * 0.05)\n",
    "    t1 = np.arange(b - ran, b + ran, ran * 0.05)\n",
    "    C = np.zeros([len(t0),len(t1)])\n",
    "    c = cost_function_para(linear_hypothesis_para, x, y)\n",
    "    for i, t_0 in enumerate(t0):\n",
    "        for j, t_1 in enumerate(t1):\n",
    "            C[j][i] = c(t_0, t_1)\n",
    "    T0, T1 = np.meshgrid(t0, t1)\n",
    "    plt.contour(T0, T1, C)\n",
    "    plt.xlabel('$\\Theta_0$')\n",
    "    plt.ylabel('$\\Theta_1$')\n",
    "    plt.title('Kostenfunktion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5)\n",
    "    Implementieren Sie das Gradientenabstiegsverfahren unter Benutzung der Kostenfunktion und der linearen  Hypothese.\n",
    "  5a) Schreiben Sie eine Funktion die die Update Rules anwendet zur Berechnung der neuen theta-Werte:\n",
    "      theta_0, theta_1 = compute_new_theta(x, y, theta_0, theta_1, alpha)\n",
    "  \n",
    "  5b) Wählen Sie Startwerte in der Umgebung des Miniums der Kostenfunktion für theta.\n",
    "      Wenden Sie iterativ die compute_new_theta Funktion an und finden Sie so ein Theta mit niedrigen Kosten.\n",
    "     \n",
    "  5c) Plotten Sie den Fortschritt (Verringerung der Kosten über den Iterationen) für 5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a\n",
    "def compute_new_theta(x, y, theta_0, theta_1, alpha):\n",
    "    tmp_theta_0 = theta_0 - alpha * (float(1)/len(y)) * np.sum(theta_0 + theta_1 * x-y)\n",
    "    tmp_theta_1 = theta_1 - alpha * (float(1)/len(y)) * np.sum((theta_0+theta_1 * x-y) * x)\n",
    "    theta_0 = tmp_theta_0\n",
    "    theta_1 = tmp_theta_1\n",
    "    return theta_0, theta_1\n",
    "\n",
    "\n",
    "# theta_0, theta_1 = compute_new_theta(x, y, 1, 1, 0.01)\n",
    "# print(\"theta_0: \", theta_0, \" theta_1: \", theta_1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b\n",
    "def iterative_gradient_descent(epochs,theta_0,theta_1,l_rate, x,y):\n",
    "    costs_list = np.array([])\n",
    "    costs = cost_function(linear_hypothesis,x,y)\n",
    "    \n",
    "    plt.title('Gradientenabstieg')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.plot([i for i in range(0,len(y))],y)\n",
    "    \n",
    "    mark_10_percent = (epochs * 10) / 100\n",
    "    mark_10_multiplier = 1\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        kosten = costs(theta_0,theta_1)\n",
    "        #print(kosten)\n",
    "        costs_list = np.append(costs_list,kosten)\n",
    "        theta_0, theta_1 = compute_new_theta(x, y, theta_0, theta_1, l_rate)\n",
    "        if i%10 == 0:\n",
    "            #print(\"epoch: \", i, \" theta_0: \", theta_0, \" theta_1: \", theta_1, \"costs: \", kosten)    \n",
    "            new_hypothesis = linear_hypothesis(theta_0, theta_1)\n",
    "            regression_model_test_values = new_hypothesis(x)\n",
    "            plt.plot([i for i in range(0,len(regression_model_test_values))],regression_model_test_values)\n",
    "        if i%mark_10_percent==0 and i is not 0:\n",
    "            #print(\"------------------------------------------  \", mark_10_multiplier*10,\"% mark reached  ----------------------------------------------------------\")\n",
    "            mark_10_multiplier+=1\n",
    "            \n",
    "    plt.show()\n",
    "    return costs_list, theta_0, theta_1\n",
    "\n",
    "\n",
    "        \n",
    "# costs_list = iterative_gradient_descent(100, np.random.normal(0, 10), np.random.normal(0, 10), 0.0001)\n",
    "# print(costs_list.shape)\n",
    "# print(\"Kosten: \\n\", costs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6)  \n",
    "   Plotten Sie das Modell (Fit-Gerade) zusammen mit den Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 7)\n",
    "    Trainieren (siehe 5b) für verschiedene Werte der Lernrate und\n",
    "    plotten Sie Kosten über den Iterationen in einen Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151436d222ad48b4a7d9491db9aec5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6b34dad01842688ddb0698fa5254f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cd9736c1d042a6bd1407bda57c5fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e372cc3816b4db0a34c7173164a1c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2d3cc8fcf743c9bbd015921fceb3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x = np.arange(0,10)\n",
    "    y= np.array([((np.random.normal()*2)+ i) for i in x])\n",
    "    alpha_richtig = 0.0009\n",
    "    alpha_test_1 = 0.001\n",
    "    alpha_test_2 = 0.00001\n",
    "    epochs = 5000\n",
    "    theta_0_start = 1\n",
    "    theta_1_start = 0.1\n",
    "    \n",
    "    plot_dataframe_with_args([[i for i in range(0,len(y))],y])\n",
    "\n",
    "    create_contour_plot(cost_function,linear_hypothesis, x, y)\n",
    "    \n",
    "    \n",
    "    costs_list, theta_0, theta_1 = iterative_gradient_descent(epochs,theta_0_start,theta_1_start,alpha_test_1,x,y)\n",
    "    plot_dataframe_with_args([[i for i in range(0,len(costs_list))],costs_list])\n",
    "\n",
    "        \n",
    "    costs_list, theta_0, theta_1 = iterative_gradient_descent(epochs,theta_0_start,theta_1_start,alpha_test_2,x,y)\n",
    "    plot_dataframe_with_args([[i for i in range(0,len(costs_list))],costs_list])\n",
    "\n",
    "    \n",
    "    costs_list, theta_0, theta_1 = iterative_gradient_descent(epochs,theta_0_start,theta_1_start,alpha_richtig,x,y)\n",
    "    \n",
    "    plot_dataframe_with_args([[i for i in range(0,len(costs_list))],costs_list])\n",
    "    \n",
    "    new_hypothesis = linear_hypothesis(theta_0, theta_1)\n",
    "    regression_model_y_values = new_hypothesis(x)\n",
    "    \n",
    "    plot_dataframe_with_args([[i for i in range(0,len(regression_model_y_values))],regression_model_y_values],[[i for i in range(0,len(y))],y])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
